{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "path = '../data/tocs/'\n",
    "files = [path+i for i in os.listdir(path)]\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(files)\n",
    "\n",
    "# train\n",
    "for file in files[:-20]:\n",
    "    img = cv2.imread(file)\n",
    "    cv2.imwrite('../data/train/'+file.split('/')[-1], img)\n",
    "\n",
    "# test\n",
    "for file in files[-20:]:\n",
    "    img = cv2.imread(file)\n",
    "    cv2.imwrite('../data/test/'+file.split('/')[-1], img)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python eval.py --checkpoint_path=./checkpoint/model-5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import config as cfg\n",
    "\n",
    "def visualization(image_path, points, label, vis_color = (255,255,255)):\n",
    "    \"\"\"\n",
    "    Visualize groundtruth label to image.\n",
    "    \"\"\"\n",
    "    points = np.asarray(points, dtype=np.int32)\n",
    "    points = np.reshape(points, [-1,2])\n",
    "    image = cv2.imread(image_path)\n",
    "    cv2.polylines(image, [points], 1, (0,255,0), 2)\n",
    "    image = Image.fromarray(image)\n",
    "    FONT = ImageFont.truetype(font_path, 20, encoding='utf-8')   \n",
    "    DRAW = ImageDraw.Draw(image)  \n",
    "    \n",
    "    DRAW.text(points[0], label, vis_color, font=FONT)\n",
    "    return np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/dy/test\n",
      "51\n",
      "\u001b[32m[0321 01:44:06 @collection.py:146]\u001b[0m New collections created in tower : tf.GraphKeys.MODEL_VARIABLES of size 452, tf.GraphKeys.REGULARIZATION_LOSSES of size 124\n",
      "\u001b[32m[0321 01:44:06 @collection.py:165]\u001b[0m These collections were modified but restored in : (tf.GraphKeys.SUMMARIES: 0->45), (tf.GraphKeys.UPDATE_OPS: 0->226)\n",
      "\u001b[32m[0321 01:44:06 @sessinit.py:87]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the checkpoint, but not found in the graph: global_step, learning_rate\n",
      "\u001b[32m[0321 01:44:10 @sessinit.py:114]\u001b[0m Restoring checkpoint from ./checkpoint/model-5000 ...\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/model-5000\n",
      "total_num: 51, 1-N.E.D: 0.9020, average time: 0.1203\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import config as cfg\n",
    "from common import polygons_to_mask\n",
    "\n",
    "from model.tensorpack_model import *\n",
    "\n",
    "from tensorpack.predict import MultiTowerOfflinePredictor, OfflinePredictor, PredictConfig\n",
    "from tensorpack.tfutils import SmartInit, get_tf_version_tuple\n",
    "from tensorpack.tfutils.export import ModelExporter\n",
    "\n",
    "def cal_sim(str1, str2):\n",
    "    \"\"\"\n",
    "    Normalized Edit Distance metric (1-N.E.D specifically)\n",
    "    \"\"\"\n",
    "    m = len(str1) + 1\n",
    "    n = len(str2) + 1\n",
    "    matrix = np.zeros((m, n))\n",
    "    for i in range(m):\n",
    "        matrix[i][0] = i\n",
    "        \n",
    "    for j in range(n):\n",
    "        matrix[0][j] = j\n",
    "\n",
    "    for i in range(1, m):\n",
    "        for j in range(1, n):\n",
    "            if str1[i - 1] == str2[j - 1]:\n",
    "                matrix[i][j] = matrix[i - 1][j - 1]\n",
    "            else:\n",
    "                matrix[i][j] = min(matrix[i - 1][j - 1], min(matrix[i][j - 1], matrix[i - 1][j])) + 1\n",
    "    \n",
    "    lev = matrix[m-1][n-1]\n",
    "    if (max(m-1,n-1)) == 0:\n",
    "        sim = 1.0\n",
    "    else:\n",
    "        sim = 1.0-lev/(max(m-1,n-1))\n",
    "    return sim\n",
    "\n",
    "\n",
    "def preprocess(image, points, size=cfg.image_size):\n",
    "    \"\"\"\n",
    "    Preprocess for test.\n",
    "    Args:\n",
    "        image: test image\n",
    "        points: text polygon\n",
    "        size: test image size\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    mask = polygons_to_mask([np.asarray(points, np.float32)], height, width)\n",
    "    x, y, w, h = cv2.boundingRect(mask)\n",
    "    mask = np.expand_dims(np.float32(mask), axis=-1)\n",
    "    image = image * mask\n",
    "    image = image[y:y+h, x:x+w,:]\n",
    "\n",
    "    new_height, new_width = (size, int(w*size/h)) if h>w else (int(h*size/w), size)\n",
    "    image = cv2.resize(image, (new_width, new_height))\n",
    "\n",
    "    if new_height > new_width:\n",
    "        padding_top, padding_down = 0, 0\n",
    "        padding_left = (size - new_width)//2\n",
    "        padding_right = size - padding_left - new_width\n",
    "    else:\n",
    "        padding_left, padding_right = 0, 0\n",
    "        padding_top = (size - new_height)//2\n",
    "        padding_down = size - padding_top - new_height\n",
    "\n",
    "    image = cv2.copyMakeBorder(image, padding_top, padding_down, padding_left, padding_right, borderType=cv2.BORDER_CONSTANT, value=[0,0,0])\n",
    "\n",
    "    image = image/255.\n",
    "    return image\n",
    "\n",
    "\n",
    "def label2str(preds, probs, label_dict, eos='EOS'):\n",
    "    \"\"\"\n",
    "    Predicted sequence to string. \n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for idx in preds:\n",
    "        if label_dict[idx] == eos:\n",
    "            break\n",
    "        results.append(label_dict[idx])\n",
    "\n",
    "    probabilities = probs[:min(len(results)+1, cfg.seq_len+1)]\n",
    "    return ''.join(results), probabilities\n",
    "\n",
    "def eval(args, filenames, polygons, labels, label_dict=cfg.label_dict):\n",
    "    Normalized_ED = 0.\n",
    "    total_num = 0\n",
    "    total_time = 0\n",
    "\n",
    "    model = AttentionOCR()\n",
    "    predcfg = PredictConfig(\n",
    "        model=model,\n",
    "        session_init=SmartInit(args['checkpoint_path']),\n",
    "        input_names=model.get_inferene_tensor_names()[0],\n",
    "        output_names=model.get_inferene_tensor_names()[1])\n",
    "\n",
    "    predictor = OfflinePredictor(predcfg)\n",
    "\n",
    "    for filename, points, label in zip(filenames, polygons, labels):\n",
    "        image = cv2.imread(filename)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = preprocess(image, points, cfg.image_size)\n",
    "\n",
    "        before = time.time()\n",
    "        preds, probs = predictor(np.expand_dims(image, axis=0), np.ones([1,cfg.seq_len+1], np.int32), False, 1.)\n",
    "        after = time.time()\n",
    "\n",
    "        total_time += after - before\n",
    "        preds, probs = label2str(preds[0], probs[0], label_dict)\n",
    "        # print('label:',label)\n",
    "        # print('pred:',preds, probs)\n",
    "\n",
    "        # sim = cal_sim(preds, label)\n",
    "        sim = 1 if str(preds) in label else 0\n",
    "\n",
    "        total_num += 1\n",
    "        Normalized_ED += sim\n",
    "        \n",
    "        # show img\n",
    "        # img = visualization(filename, polygon, transcript)\n",
    "        # plt.imshow(image)\n",
    "        # plt.show()\n",
    "\n",
    "    print(\"total_num: %d, 1-N.E.D: %.4f, average time: %.4f\" % (total_num, Normalized_ED/total_num, total_time/total_num))\n",
    "\n",
    "\n",
    "\n",
    "args = {'checkpoint_path':'./checkpoint/model-5000'}\n",
    "from dataset import DY\n",
    "\n",
    "DY = DY('dy_test')\n",
    "DY.load_data()\n",
    "print(len(DY.filenames))\n",
    "\n",
    "eval(args, DY.filenames, DY.points, DY.transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python export.py --pb_path=./pb/dingyu.pb --checkpoint_path=./checkpoint/model-5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --pb_path=./pb/dingyu.pb --img_folder=../data/dy/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import config as cfg\n",
    "import tensorflow as tf\n",
    "from common import polygons_to_mask\n",
    "\n",
    "class TextRecognition(object):\n",
    "    \"\"\"\n",
    "    AttentionOCR with tensorflow pb model.\n",
    "    \"\"\"\n",
    "    def __init__(self, pb_file, seq_len):\n",
    "        self.pb_file = pb_file\n",
    "        self.seq_len = seq_len\n",
    "        self.init_model()\n",
    "        \n",
    "    def init_model(self):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            with tf.gfile.FastGFile(self.pb_file, 'rb') as f:\n",
    "                graph_def = tf.GraphDef()\n",
    "                graph_def.ParseFromString(f.read())\n",
    "                _ = tf.import_graph_def(graph_def, name='')\n",
    "        \n",
    "        \n",
    "        self.sess = tf.Session(graph=self.graph)\n",
    "        \n",
    "        self.img_ph = self.sess.graph.get_tensor_by_name('image:0')\n",
    "        self.label_ph = self.sess.graph.get_tensor_by_name('label:0')\n",
    "        self.is_training = self.sess.graph.get_tensor_by_name('is_training:0')\n",
    "        self.dropout = self.sess.graph.get_tensor_by_name('dropout_keep_prob:0')\n",
    "        self.preds = self.sess.graph.get_tensor_by_name('sequence_preds:0')\n",
    "        self.probs = self.sess.graph.get_tensor_by_name('sequence_probs:0')\n",
    "        \n",
    "    def predict(self, image, label_dict, EOS='EOS'):\n",
    "        results = []\n",
    "        probabilities = []\n",
    "        \n",
    "        pred_sentences, pred_probs = self.sess.run([self.preds, self.probs], \\\n",
    "                    feed_dict={self.is_training: False, self.dropout: 1.0, self.img_ph: image, self.label_ph: np.ones((1,self.seq_len), np.int32)})\n",
    "\n",
    "        for char in pred_sentences[0]:\n",
    "            if label_dict[char] == EOS:\n",
    "                break\n",
    "            results.append(label_dict[char])\n",
    "        probabilities = pred_probs[0][:min(len(results)+1,self.seq_len)]\n",
    "        \n",
    "        return results, probabilities\n",
    "\n",
    "def preprocess(image, points, size=cfg.image_size):\n",
    "    \"\"\"\n",
    "    Preprocess for test.\n",
    "    Args:\n",
    "        image: test image\n",
    "        points: text polygon\n",
    "        size: test image size\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    mask = polygons_to_mask([np.asarray(points, np.float32)], height, width)\n",
    "    x, y, w, h = cv2.boundingRect(mask)\n",
    "    mask = np.expand_dims(np.float32(mask), axis=-1)\n",
    "    image = image * mask\n",
    "    image = image[y:y+h, x:x+w,:]\n",
    "\n",
    "    new_height, new_width = (size, int(w*size/h)) if h>w else (int(h*size/w), size)\n",
    "    image = cv2.resize(image, (new_width, new_height))\n",
    "\n",
    "    if new_height > new_width:\n",
    "        padding_top, padding_down = 0, 0\n",
    "        padding_left = (size - new_width)//2\n",
    "        padding_right = size - padding_left - new_width\n",
    "    else:\n",
    "        padding_left, padding_right = 0, 0\n",
    "        padding_top = (size - new_height)//2\n",
    "        padding_down = size - padding_top - new_height\n",
    "\n",
    "    image = cv2.copyMakeBorder(image, padding_top, padding_down, padding_left, padding_right, borderType=cv2.BORDER_CONSTANT, value=[0,0,0])\n",
    "\n",
    "    image = image/255.\n",
    "    return image\n",
    "\n",
    "def test(args):\n",
    "    model = TextRecognition(args['pb_path'], cfg.seq_len+1)\n",
    "    \n",
    "    \n",
    "    for filename in os.listdir(args['img_folder']):\n",
    "        img_path = os.path.join(args['img_folder'], filename)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        points = [[0,0], [width-1,0], [width-1,height-1], [0,height-1]]\n",
    "\n",
    "        image = preprocess(image, points, cfg.image_size)\n",
    "        image = np.expand_dims(image, 0)\n",
    "        \n",
    "        before = time.time()\n",
    "        preds, probs = model.predict(image, cfg.label_dict)\n",
    "        after = time.time()\n",
    "\n",
    "        print(preds, probs)\n",
    "\n",
    "        plt.imshow(image[0,:,:,:])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args = {'pb_path':'./pb/dingyu.pb','img_folder':'../data/dy/test'}\n",
    "test(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
